---
show: step
version: 1.0 
---

## 课程介绍

本课程将介绍 Spark SQL 支持的一些常见数据类型，以及 Spark SQL 数据类型和 SequoiaDB 数据类型的映射关系。实验过程中将通过 JDBC 在 Spark SQL 中创建 SequoiaDB 集合的映射表，并插入不同类型的数据，观察不同数据类型在 Spark 和 SequoiaDB 中的兼容情况。

#### 知识点

**数据类型映射关系**

| SequoiaDB 类型 | SparkSQL 类型 | SQL 实例类型            |
| -------------- | ------------- | ----------------------- |
| int32          | IntegerType   | int                     |
| int64          | LongType      | bigint                  |
| double         | DoubleType    | double                  |
| decimal        | DecimalType   | decimal                 |
| string         | StringType    | string                  |
| ObjectId       | StringType    | string                  |
| boolean        | BooleanType   | boolean                 |
| date           | DateType      | date                    |
| timestamp      | TimestampType | timestamp               |
| binary         | BinaryType    | binary                  |
| null           | NullType      | null                    |
| BSON(嵌套对象) | StructType    | struct < field:type,… > |
| array          | ArrayType     | array < type >          |

* 数组类型

  Spark 的 **ArrayType** 数据类型为由 elementType 类型元素组成的序列值。指定字段类型为 ArrayType 写法如下：

  ```sql
  字段名 array<数组元素类型>
  ```

* 结构化类型

  Spark 的 **StructType** 数据类型为一个拥有 **StructFields** (fields) 序列结构的值，StructField(name, dataType, nullable) 代表 StructType 中的一个字段，字段的名字通过 name 指定，dataType 指定field的数据类型，nullable 表示字段的值是否有null值。指定字段类型为 StructType 写法如下：

  ```sql
  字段名 struct<key:key类型,val:value类型>
  ```

  > 说明
  >
  > StructType 类型中可以嵌套其他类型，例如：
  >
  > ```sql
  > StructType struct<key:int,val:array<int>>
  > ```

**指定关联表的数据类型**

在上一章中介绍了 Spark 在创建映射表时会自动生成表结构，实际上也可以手动指定映射表的表结构。

以本课程使用到的 typelist 表为例：

![1738-430-映射](https://doc.shiyanlou.com/courses/1738/1207281/f0a1a35e4d634495eb90deacb0102054-0)

> **说明**
>
> 在配置映射的 options 中，由于 SequoiaDB 的连接鉴权默认是无密码的，用户名和密码在此可以省略

#### 实验环境

当前实验的系统和软件环境如下：

* Ubuntu 16.04.6 LTS
* JDK version "1.8.0_172"
* Spark version: 2.4.3
* SequoiaDB version: 3.4
* SequoiaSQL-MySQL version: 3.4
* IntelliJ IDEA Community Version: 2019.3.4

## 打开项目

#### 打开 IDEA

打开 IDEA 代码开发工具

![1738-410-07](https://doc.shiyanlou.com/courses/1738/1207281/72397a857808ab74f01b042f07ea0a27-0)

#### 打开 SCDD-Spark 项目

选择 Spark 课程项目

![1738-410-08](https://doc.shiyanlou.com/courses/1738/1207281/6d46a0bb22fac49997e6606ec1a128ab-0)

#### 打开当前实验的 Package

如图所示找到当前实验使用的程序所在 Package

![1738-430-04](https://doc.shiyanlou.com/courses/1738/1207281/a046235d6ea13f4356eeafde43cef769-0)

#### Maven 依赖

如图所示找到 pom.xml 文件：

![pom](https://doc.shiyanlou.com/courses/1738/1207281/4474b7a73c5469e7315fc9a153d73ccc-0)

在 pom.xml 文件中可以找到当前实验使用到的 Maven 依赖：

![1738-430-maven](https://doc.shiyanlou.com/courses/1738/1207281/a2a6cd1e26b7722ce16e98c292a9ff66-0)

## 程序代码

程序将在 SequoiaDB 中自动初始化一个名为 typelist 的集合，并在 Spark SQL 中创建 typelist 集合的映射表（指定表结构创建），通过 JDBC 向 typelist 表中插入一条包含常见数据类型字段的记录，分别在 Spark 表和 SequoiaDB 集合中查询该记录观察各种数据类型字段的存储情况。

#### 创建关联表

如图所示找到 com.sequoiadb.lesson.spark.lesson3_datatype.CreataTable 类：

![1738-430-05](https://doc.shiyanlou.com/courses/1738/1207281/32e84090e99b0791495b170c5bc165ed-0)

程序中会自动调用预定义的方法初始化 SequoiaDB 集合，以下是创建 SequoiaDB 集合的映射表代码内容：

```java
// Drop the existing typelist table
String dropTable="DROP TABLE IF EXISTS typelist";
// Call HiveUtil to execute sql
HiveUtil.doDDL(dropTable);
// Create Spark Table and specify the data type of each field
String linkCollection=
        "CREATE TABLE typelist(" +
                "IntegerType int," +
                "LongType bigint," +
                "DoubleType double," +
                "DecimalType decimal(10,1)," +
                "StringType string," +
                "BooleanType boolean," +
                "DateType date," +
                "TimestampType timestamp," +
                "BinaryType binary," +
                "ArrayType array<int>," +
                "StructType struct<key:int,val:array<int>>" +
                ") USING com.sequoiadb.spark " +
                "OPTIONS(" +
                "host 'sdbserver1:11810'," +
                "collectionspace 'sample'," +
                "collection 'typelist'" +
                ")";
// Call HiveUtil to execute sql
HiveUtil.doDDL(linkCollection);
```

将上述代码粘贴至 createTable 类 createTable 方法的 TODO code1 注释区间内：

![1738-430-06](https://doc.shiyanlou.com/courses/1738/1207281/41cfbfd2559f32d93678f135df5419ff-0)

#### 插入数据

如图所示找到 com.sequoiadb.lesson.spark.lesson3_datatype.DataOperation 类：

![1738-430-07](https://doc.shiyanlou.com/courses/1738/1207281/aff1ec1f8b051de94048135f05f7698f-0)

通过映射表向 SequoiaDB 集合中插入含有不同数据类型的数据，代码内容如下：

```java
// Insert record (different types of fields)
String insertSql =
        "INSERT INTO typelist " +
                "VALUES(" +
                "1," +
                "9223372036854775807," +
                "3.1415," +
                "3.14," +
                "\"abc\"," +
                "true," +
                "current_date()," +
                "current_timestamp()," +
                "encode(\"qazwsxedc\",\"UTF-8\")," +
                "array(1,2,3)," +
                "struct(123,array(1,2,3))" +
                ")";
// Call HiveUtil to execute sql statement
HiveUtil.doDML(insertSql);
```

将上述代码粘贴至 DataOperation 类 insertData 的 TODO code 2 注释区间内：

![1738-430-08](https://doc.shiyanlou.com/courses/1738/1207281/e3eb4849be13e058844fde6fb628e86d-0)

## 运行程序

#### 运行主函数

右键点击 DataTypeMainTest 类选择 `Run` 运行主类：

![1738-430-09](https://doc.shiyanlou.com/courses/1738/1207281/fced2bfbd9f7f3366902aa5f6c5e7068-0)

#### 查看运行结果

程序运行结果如下图所示：

![1738-430-10](https://doc.shiyanlou.com/courses/1738/1207281/34a13b25be7e98b1fc25549c49e3eeef-0)

## 总结

本课程介绍了 Spark SQL 常见的数据类型以及它们和 SequoiaDB 支持的数据类型的映射关系，并通过实验在 Spark 中创建外部映射表的方式访问 SequoiaDB 集合并插入包含不同数据类型的记录，验证不同的数据类型在 Spark 和 SequoiaDB 的兼容能力。
