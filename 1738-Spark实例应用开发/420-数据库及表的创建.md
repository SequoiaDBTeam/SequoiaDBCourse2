---
show: step
version: 1.0 
---

## 课程介绍

本课程将介绍如何通过 JDBC 在 Spark SQL 中创建 SequoiaDB 集合的关联表。

#### 知识点

在 Spark SQL 中支持 SQL API 在 Spark 中建表并映射外部数据源，只要在 Spark 中创建了外部数据源的映射表，就可以通过 JDBC 访问 Spark 外部数据源。

在 Spark 中创建映射表只需要指定数据源，无需定义表结构，在映射时 Spark 会根据结构化数据源自动生成表结构。以创建 SequoiaDB 集合空间的映射表为例，创建表语法及参数说明如下（详见 巨杉官网：http://doc.sequoiadb.com/cn/sequoiadb-cat_id-1432190712-edition_id-0）：

![1738-420-驱动](https://doc.shiyanlou.com/courses/1738/1207281/a040460c8cb09d8a2758b94dc284e93d-0)

> **说明**
>
> com.sequoiadb.spark 为巨杉数据库开发的 Spark 连接驱动，可以在 Spark 创建表时指定和 SequoiaDB 中的集合空间映射并和集合的各个数据分区做好对接。
>
> 连接驱动可以在巨杉官网下载：http://download.sequoiadb.com/cn/driver
>
> 使用连接器需要确保 SPARK_CLASSPATH 中已添加连接驱动。

#### 实验环境

当前实验的系统和软件环境如下：

* Ubuntu 16.04.6 LTS
* JDK version "1.8.0_172"
* SequoiaDB version: 3.4
* SequoiaSQL-MySQL version: 3.4
* Spark version: 2.4.3
* IntelliJ IDEA Community Version: 2019.3.4

## 打开项目

#### 打开 IDEA

打开 IDEA 代码开发工具。

![1738-420-01](https://doc.shiyanlou.com/courses/1738/1207281/b478b77e961e05b3f8bfa0bf327a58ad-0)

#### 打开 SCDD-Spark 项目

选择 Spark 课程项目

![1738-420-02](https://doc.shiyanlou.com/courses/1738/1207281/738ff5ff514f299a6dcfaf7340367c2f-0)

#### 打开当前实验的 Package

如图所示找到当前实验使用的程序所在 Package

![1738-420-03](https://doc.shiyanlou.com/courses/1738/1207281/ac943cd641aa2deb90121563e07f49ac-0)

#### Maven 依赖

如图所示找到 pom.xml 文件：

![pom](https://doc.shiyanlou.com/courses/1738/1207281/4474b7a73c5469e7315fc9a153d73ccc-0)

在 pom.xml 文件中可以找到当前实验使用到的 Maven 依赖：

![1738-420-04](https://doc.shiyanlou.com/courses/1738/1207281/d2169f36c0d88c23f13ac644f3055eba-0)

## 映射 SequoiaDB 集合

程序将通过 SequoiaSQL-MySQL 实例初始化 employee 表存储到 SequoiaDB 中，通过 Hive on Spark 建立和 SequoiaDB 的 employee 集合的映射表进行查询。

#### 打开 CreateTable 类

如图所示打开 com.sequoiadb.lesson.spark.lesson2_createtable.CreateTable 类准备编写代码

![1738-420-05](https://doc.shiyanlou.com/courses/1738/1207281/4943de69caa14e92a07d9d358ebc9e50-0)

#### 创建关联表代码

通过 JDBC 提交建表语句映射 employee 集合代码如下：

```java
// Init table
String dropTable =
        "DROP TABLE IF EXISTS employee";
// Call the method of HiveUtil to init the employee table
HiveUtil.doDDL(dropTable);
// Create a Spark table (associate with the employee collection of SequoiaDB)
String createLinkTable =
        "CREATE TABLE employee " +
                "USING com.sequoiadb.spark  " +
                "OPTIONS( " +
                "host 'sdbserver1:11810', " +
                "collectionspace 'sample', " +
                "collection 'employee', " +
                "user 'sdbadmin'," +
                "password 'sdbadmin'" +
                ")";
// Call the method of HiveUtil to execute the sql statement
System.out.println("Creating Spark table...");
HiveUtil.doDDL(createLinkTable);
// View the Spark table structure
String getDesc=
        "DESC employee";
// Call the method of HiveUtil to query the table structure
System.out.println("Getting the structure of employee...");
HiveUtil.doDQL(getDesc);
// Query the result set of Spark table
String queryTable = "SELECT id,name,sex,birth,phone,email,position,address FROM employee";
// Call the method of HiveUtil to query the result set of Spark table
System.out.println("Getting the result set of employee...");
HiveUtil.doDQL(queryTable);
```

将上述代码粘贴至 CreateTable 类 createTable 方法的 TODO code 1 注释区间内：

![1738-420-06](https://doc.shiyanlou.com/courses/1738/1207281/9955788b132984638cda50bc21d1e51f-0)

## 运行程序

#### 运行主函数

右键点击 CreateTableMainTest 选择 Run 主函数

![1738-420-07](https://doc.shiyanlou.com/courses/1738/1207281/6cd80ce4cdb43d896a9fe98e65c99d4b-0)

#### 运行结果

程序运行结果如下图所示，分别展示了 MySQL 实例中的 employee 表和 Spark SQL 映射表的结果集：

![1738-420-08](https://doc.shiyanlou.com/courses/1738/1207281/fb78215e5c42795bd3a4021100c402c9-0)

从 Spark 映射表的表结构可以看出，即便在映射时没有指定表结构，Spark 也会自动为各个字段匹配相应的数据类型。

## 总结

本课程介绍了如何通过 JDBC 在 Spark 中创建 SequoiaDB 集合的映射表，并通过 JDBC 的方式访问映射表表。在 Spark SQL 中创建 SequoiaDB 集合的映射表时，Spark 会自动生成映射表的表结构。
