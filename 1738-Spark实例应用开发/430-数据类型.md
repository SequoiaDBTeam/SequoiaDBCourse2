---
show: step
version: 1.0 
---

## 课程介绍

本课程将介绍 Spark SQL 支持的一些常见数据类型，以及 Spark SQL 数据类型和 SequoiaDB 数据类型的映射关系。实验过程中将通过 JDBC 在 Hive on Spark 中创建 SequoiaDB 的关联表，并插入不同类型的数据，观察不同数据类型分别在 Spark 和 SequoiaDB 中的兼容情况。

#### 实验环境

当前实验的系统和软件环境如下：

* Ubuntu 16.04.6 LTS
* JDK version "1.8.0_172"
* spark version: 2.4.3
* SequoiaDB version: 3.4
* SequoiaSQL-MySQL version: 3.4
* IntelliJ IDEA Community Version: 2019.3.4

#### 知识点

**数据类型映射关系**

| SequoiaDB 类型 | SparkSQL 类型 | SQL 实例类型            |
| -------------- | ------------- | ----------------------- |
| int32          | IntegerType   | int                     |
| int64          | LongType      | bigint                  |
| double         | DoubleType    | double                  |
| decimal        | DecimalType   | decimal                 |
| string         | StringType    | string                  |
| ObjectId       | StringType    | string                  |
| boolean        | BooleanType   | boolean                 |
| date           | DateType      | date                    |
| timestamp      | TimestampType | timestamp               |
| binary         | BinaryType    | binary                  |
| null           | NullType      | null                    |
| BSON(嵌套对象) | StructType    | struct < field:type,… > |
| array          | ArrayType     | array < type >          |

* 数组类型

  Spark 的 **ArrayType** 数据类型为由 elementType 类型元素组成的序列值。指定字段类型为 ArrayType 写法如下：

  ```sql
  字段名 array<数组元素类型>
  ```

* 结构化类型

  Spark 的 **StructType** 数据类型为一个拥有 **StructFields** (fields) 序列结构的值，StructField(name, dataType, nullable) 代表 StructType 中的一个字段，字段的名字通过 name 指定，dataType 指定field的数据类型，nullable 表示字段的值是否有null值。指定字段类型为 StructType 写法如下：

  ```sql
  字段名 struct<key:key类型,val:value类型>
  ```

  > 说明
  >
  > StructType 类型中可以嵌套其他类型，例如：
  >
  > ```sql
  > StructType struct<key:int,val:array<int>>
  > ```

**指定关联表的数据类型**

在上一章中介绍了 Spark 在创建关联表时会自动生成关联表的表结构，实际上也可以手动指定关联表的表结构。

![1738-430-01](https://doc.shiyanlou.com/courses/1738/1207281/d0f8642be1a0faa8b242428311d6d747-0)

在配置关联的 options 中，默认安装的 SequoiaDB 用户名和密码都为 sdbadmin，在此可以省略。以本课程使用到的 typelist 表为例，以下是创建关联表的写法以及有关配置项说明：

![1738-430-关联](https://doc.shiyanlou.com/courses/1738/1207281/7c3af7ea122cd14d096f559f087ee778-0)

## 打开项目

#### 打开 IDEA

打开 IDEA 代码开发工具

![1738-430-02](https://doc.shiyanlou.com/courses/1738/1207281/a37d1edef54f61d8494149eb63211bb0-0)

#### 打开 SCDD-Spark 项目

选择 Spark 课程项目

![1738-430-03](https://doc.shiyanlou.com/courses/1738/1207281/ef0a2018293449ad911cf79593b994c3-0)

#### 打开当前实验的 Package

如图所示找到当前实验使用的程序所在 Package

![1738-430-04](https://doc.shiyanlou.com/courses/1738/1207281/8a4d03313e06908519ab1b5516d6b22e-0)

#### Maven 依赖

在 pom.xml 中可以找到当前实验中使用到的 Maven 依赖：

![1738-430-maven](https://doc.shiyanlou.com/courses/1738/1207281/a2a6cd1e26b7722ce16e98c292a9ff66-0)

## 程序代码

程序将在 SequoiaDB 中 初始化一个名为 typelist 的集合，并在 Hive on Spark 中创建 typelist 集合的关联表（指定表结构创建），通过 JDBC 向 typelist 表中插入一条包含常见数据类型字段的记录，分别在 Hive

#### 创建关联表

如图所示找到 com.sequoiadb.lesson.spark.lesson3_datatype.LinkCollection 类：

![1738-430-05](https://doc.shiyanlou.com/courses/1738/1207281/428085732148f52ac781cddadea880cb-0)

程序中会自动调用预定义的方法初始化 SequoiaDB 集合，以下是创建集合的关联表的代码内容：

```java
// drop 已有的 typelist 表
String dropTable="drop table if exists typelist";
// 调用 HiveUtil 工具执行 sql
HiveUtil.doDDL(dropTable);
// 创建 SequoiaDB 集合的关联表并指定各个字段的数据类型
String linkCollection=
        "create table typelist(" +
                "IntegerType int," +
                "LongType bigint," +
                "DoubleType double," +
                "DecimalType decimal(10,1)," +
                "StringType string," +
                "BooleanType boolean," +
                "DateType date," +
                "TimestampType timestamp," +
                "BinaryType binary," +
                "ArrayType array<int>," +
                "StructType struct<key:int,val:array<int>>" +
                ") using com.sequoiadb.spark " +
                "options(" +
                "host 'master:11810'," +
                "collectionspace 'sample'," +
                "collection 'typelist'" +
                ")";
// 调用 HiveUtil 工具执行 sql
HiveUtil.doDDL(linkCollection);
```

将上述代码粘贴至 LinkCollection 类 linkCollection 方法的 TODO -- lesson3_datatype:code1 注释中（33 行）：

![1738-430-06](https://doc.shiyanlou.com/courses/1738/1207281/9931df609caeec32a7f2e0ddb0bc327b-0)

#### 插入数据

如图所示找到 com.sequoiadb.lesson.spark.lesson3_datatype.DataOperation 类：

![1738-430-07](https://doc.shiyanlou.com/courses/1738/1207281/3ee6416b52134592ed2a0a47369a7613-0)

通过 Hive 关联表向 SequoiaDB 集合中插入含有不同数据类型的数据，代码内容如下：

```java
// 插入记录（不同类型字段）
String insertSql =
        "insert into typelist " +
                "values(" +
                "1," +
                "9223372036854775807," +
                "3.1415," +
                "3.14," +
                "\"abc\"," +
                "true," +
                "current_date()," +
                "current_timestamp()," +
                "encode(\"qazwsxedc\",\"UTF-8\")," +
                "array(1,2,3)," +
                "struct(123,array(1,2,3))" +
                ")";
// 调用 HiveUtil 工具累执行 sql 语句
HiveUtil.doDML(insertSql);
```

将上述代码粘贴至 DataOperation 类 insertData 的 TODO -- lesson3_datatype:code2 注释中（21 行）：

![1738-430-08](https://doc.shiyanlou.com/courses/1738/1207281/abe196a5797ebfe8c9f20fb7a35f2ab4-0)

## 运行程序

#### 运行主函数

右键点击 DataTypeMainTest 类选择 `Run` 运行主类：

![1738-430-09](https://doc.shiyanlou.com/courses/1738/1207281/ed34110f339c44028eed494ed8567bc9-0)

#### 查看运行结果

程序运行结果如下图所示：

![1738-430-10](https://doc.shiyanlou.com/courses/1738/1207281/7e3a493fb1ff185c8e6f8942c524c103-0)

> **说明**
>
> 记录在 SequoiaDB 引擎中是以 BSON 对象的形式存储，为了更清晰地展示查询效果这里做了格式化打印的处理。

## 总结

本课程介绍了 Spark SQL 常见的数据类型以及它们和 SequoiaDB 支持的数据类型的映射关系，并通过实验创建外表的形式访问 SequoiaDB 集合数据插入包含不同数据类型的记录并查询记录，来查看 Spark 和 SequoiaDB 对不同数据类型的支持能力。
